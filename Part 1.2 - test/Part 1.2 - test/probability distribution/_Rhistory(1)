#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages(ggExtra)
#----------------------------------------------------------------------------------
# Animated Bubble chart visulization
install.packages("cowplot")
install.packages("gganimate")
# ggMarginal(g, type = "density", fill="transparent")
#-----------------------------------------------------------------------
library(devtools)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages(ggExtra)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages(ggextra)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages(ggExtra)
library(ggplot2)
library(ggExtra)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages("ggExtra")
library(ggplot2)
library(ggExtra)
library(ggMarginal)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages("ggMarginal")
library(ggMarginal)
#--------------------------------------------------------------------
# Marginal Histogram / Boxplot visulization
install.packages("ggMarginal")
queue <- factor(c("f", "m", "m", "f", "m", "f", "f", "f"))
library(tseries)
runs.test(queue, alternative="greater")
runs.test(queue, alternative="less")
runs.test(queue, alternative="two.sided")
View(cv)
View(mpg)
#run test
#runs.test(x, exact = FALSE, alternative = c("two.sided", "less", "greater"))
queue <- mpg$displ
library(tseries)
runs.test(queue, alternative="two.sided")
#run test
#runs.test(x, exact = FALSE, alternative = c("two.sided", "less", "greater"))
queue <- factor(mpg$displ)
runs.test(queue, alternative="two.sided")
View(get_pred)
View(data_all)
durbinWatsonTest(lm(pred ~ ., data=data_all))
library(car)
install.packages("car")
library(car)
durbinWatsonTest(lm(pred ~ ., data=data_all))
library(lmtest)
install.packages("lmtest")
library(lmtest)
dwtest(lm(pred ~ ., data=data_all))
bgtest(pred ~ ., data=data_all)
coeftest(bgtest(pred ~ ., data=data_all))
bgtest(lm(pred ~ ., data=data_all))
coeftest(bgtest(lm(pred ~ ., data=data_all))
bgtest(lm(pred ~ .,order = 1, data=data_all))
bgtest(lm(pred ~ .,order = 1, data=data_all))
bgtest(lm(pred ~ .,order = 4, data=data_all))
bgtest(lm(pred ~ .,data=data_all))
coeftest(bgtest(lm(pred ~ ., data=data_all)))
l
fm <- lm(pred ~ ., data=data_all)
## Newey & West (1994) compute this type of estimator
NeweyWest(fm)
## fit investment equation
library(NeweyWest)
## fit investment equation
install.packages("NeweyWest")
library(NeweyWest)
fm <- lm(pred ~ ., data=data_all)
library(NeweyWest)
## Newey & West (1994) compute this type of estimator
NeweyWest(fm)
## fit investment equation
install.packages("sandwich")
library(sandwich)
fm <- lm(pred ~ ., data=data_all)
## Newey & West (1994) compute this type of estimator
NeweyWest(fm)
## The Newey & West (1987) estimator requires specification
## of the lag and suppression of prewhitening
NeweyWest(fm, lag = 4, prewhite = FALSE)
## bwNeweyWest() can also be passed to kernHAC(), e.g.
## for the quadratic spectral kernel
kernHAC(fm, bw = bwNeweyWest)
library(readxl)
TrainExer1_1 <- read_excel("C:/Users/Ami Laddani/Desktop/Econometrics Methods and Applications/simple regression_motivation_1.1/TrainExer1.1.xls")
View(TrainExer1_1)
hist_age <- TrainExer1.1$Age
hist_age <- TrainExer1_1$Age
hist(hist_age)
library(readxl)
MEAN_HOURLY_WAGE_BY_EDUCATION <- read_excel("C:/Users/Ami Laddani/Desktop/kurtosis and skewness/MEAN HOURLY WAGE BY EDUCATION.xlsx")
View(MEAN_HOURLY_WAGE_BY_EDUCATION)
# kuryosis
> library(e1071)                    # load e1071
# kuryosis
library(e1071)                    # load e1071
wage_test = MEAN HOURLY WAGE BY EDUCATION$wage     # wage test function
wage_test = MEAN_HOURLY_WAGE_BY_EDUCATION$wage     # wage test function
kurtosis(wage_test)   # apply the kurtosis function
skewness(wage_test)
summary(wage_test)
plot(density(MEAN_HOURLY_WAGE_BY_EDUCATION$wage))
hist(MEAN_HOURLY_WAGE_BY_EDUCATION$wage, breaks=100)
qqnorm(MEAN_HOURLY_WAGE_BY_EDUCATION$wage)
qqline(MEAN_HOURLY_WAGE_BY_EDUCATION)
qqline(MEAN_HOURLY_WAGE_BY_EDUCATION$wage)
plot(density(MEAN_HOURLY_WAGE_BY_EDUCATION$wage))
qplot(wage_test, geom = 'histogram', binwidth = 2) + xlab('wage_test')
library(ggplot2)
qplot(wage_test, geom = 'histogram', binwidth = 2) + xlab('wage_test')
jarque.bera.test(wage_test)
install.packages("normtest")
library(normtest)
jarque.bera.test(wage_test)
jarque.bera.norm.test(wage_test)
jb.norm.test(wage_test)
X
x
x <- list(1, "a", TRUE, 1 + 4i)
x
> x <- 1:3
x <- 1:3
y <- 10:12
cbind(x, y)
dim(m) <- c(2, 5)
m <- 1:10
dim(m) <- c(2, 5)
m <- 1:10
dim(m) <- c(2, 5)
m
x <- factor(c("yes", "yes", "no", "yes", "no"),
levels = c("yes", "no"))
x
x <- factor(c("yes", "yes", "no", "yes", "no"),
levels = c("a", "b"))
x
x <- factor(c("yes", "yes", "no", "yes", "no"),
levels = c("yes", "no"))
x
table(x)
unclass(x)
x <- matrix(1:4, 2, 2); y <- matrix(rep(10, 4), 2, 2)
x * y
x %*% y
data(cars)
# Box plot
boxplot(price ~ type, data=cars, xlab="Type", ylab="Price")
View(cars)
data(mpg)
data(MPG)
library(readxl)
ravens_data <- read_excel("E:/download/swirl_courses-master/Regression_Models/Binary_Outcomes/ravens_data.csv")
View(ravens_data)
library(readxl)
ravens_data <- read_excel("E:/download/swirl_courses-master/Regression_Models/Binary_Outcomes/ravens_data.csv")
View(ravens_data)
library(readxl)
max_sample_size <- 500
mean_vec <- rep(0, max_sample_size)
summary(mean_vec)
mean_vec
for (n in 1:max_sample_size) {
values <- sample(h95[Hc_data$SA95==1 & Hc_data$h95<90], n)
mean_vec[n] <- mean(values)
}
max_sample_size <- 500
mean_vec <- rep(0, max_sample_size)
for (n in 1:max_sample_size) {
values <- sample(h95[Hc_data$SA95==1 & Hc_data$h95<90], n)
mean_vec[n] <- mean(values)
}
plot(seq(1,max_sample_size), mean_vec, xlab="Sample size", ylab="Sample mean")
abline(h=mu, col="red")
detach(Hc_data)
set.seed(807060)
x <- sample(0:1, 10000, repl=T)
s <- cumsum(x); r <- s/(1:n)
plot(r, ylim=c(.01, .60), type=”l”)
lines(c(0,n), c(.50,.50),col=”red”)
round(cbind(x,s,r), 5)[1:10,]; r[n]
plot(r, ylim=c(.01, .60), type=”l”)
#setting a parameters of Bi(n, p)
n <- 1000
p <- 0.4
#dataframe
df <- data.frame(bi = rbinom(n, 1, p)  ,count = 0, mean = 0)
ifelse(df$bi[1] == 1, df[1, 2:3] <- 1, 0)
for (i in 2 : n){
df$count[i] <- ifelse(df$bi[i] == 1, df$count[i]<-df$count[i - 1]+1, df$count[i - 1])
df$mean[i] <- df$count[i] / i
}
#graph
plot(df$mean, type='l',
main = "Simulation of the Low of Large Numbers",
xlab="Numbers", ylab="Sample mean")
abline(h = p, col="red")
library(readxl)
Book1 <- read_excel("C:/Users/Ami Laddani/Desktop/Book1.xlsx")
View(Book1)
setwd("~/")
install.packages('caTools')
library(caTools)
set.seed(123)
regressor = lm(formula = y ~ x,
data = Book1)
regressor
setwd("C:/Users/Ami Laddani/Desktop/Machine Learning A-Z-20180620T104418Z-001/Machine Learning A-Z/Part 1.2 - test/probability distribution")
pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
pnorm(84, mean=72, sd=15.2, lower.tail=TRUE)
pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
qchisq(.95, df=7)        # 7 degrees of freedom
qt(c(.025, .975), df=5)   # 5 degrees of freedom
qt(c(.025, df=5)   # 5 degrees of freedom
qt(c(.025), df=5)   # 5 degrees of freedom
qt((.025), df=5)   # 5 degrees of freedom
qf(.95, df1=5, df2=2)
library(readxl)
Salary_Data <- read.csv("C:/Users/Ami Laddani/Desktop/Machine Learning A-Z-20180620T104418Z-001/Machine Learning A-Z/Part 2 - Regression/Section 4 - Simple Linear Regression/Salary_Data.csv")
View(Salary_Data)
qqnorm(Salary_Data$YearsExperience)
qqline(Salary_Data$YearsExperience)
help(qqplot)
qqplor(Salary_Data$YearsExperience)
qqplor(Salary_Data$Salary,Salary_Data$YearsExperience)
install.packages("qqplot")
library(qqplot)
qqplor(Salary_Data$Salary,Salary_Data$YearsExperience)
library("quantreg", lib.loc="~/R/win-library/3.4")
qqplor(Salary_Data$Salary,Salary_Data$YearsExperience)
library(qqplot)
help(qqplot)
qqplor(Salary_Data$Salary,Salary_Data$YearsExperience,plot.it = TRUE)
qqplor(Salary_Data$YearsExperience,plot.it = TRUE)
qqplot(Salary_Data$YearsExperience,plot.it = TRUE)
qqplot(Salary_Data$Salary,Salary_Data$YearsExperience,plot.it = TRUE)
#  NORMALITY TRANSFORMATION
# if normality assumption does not hold
regressor = lm(formula = Salary ~ YearsExperience,
data = Salary_Data)
plot(Salary_Data$YearsExperience,rstandard(regressor))
par(mfrow=c(2,1))
hist(regressor$resid)
hist(regressor$resid, margin = NULL)
qqnorm(regressor$resid)
qqline(regressor$resid)
library(moments)
install.packages("moments")
library(moments)
skewness(regressor$resid)
library(MASS)
b=boxcox(formula = Salary ~ YearsExperience,data = Salary_Data)
b=boxcox(Salary ~ YearsExperience,data = Salary_Data)
par("mar")
par(mfrow=c(1,1,1,1))
par(mfrow=c(1,1))
hist(regressor$resid, margin = NULL)
qqnorm(regressor$resid)
qqline(regressor$resid)
b=boxcox(Salary ~ YearsExperience,data = Salary_Data)
plot(Salary_Data$YearsExperience,rstandard(regressor))
b=boxcox(Salary ~ YearsExperience,data = Salary_Data)
b=boxcox(Salary ~ YearsExperience,data = Salary_Data)
lemda=Salary_Data$YearsExperience
lemda
lik= Salary_Data$Salary
lik
regressor
cb=cbind(lemda,lik)
cb
cb[order(-lik),]
install.packages("car")
library(car)
linearHypothesis(regressor,c(0,1),rhs=1)
help(pt)
install.packages("car")
library(car)
install.packages("car")
install.packages("car")
library(car)
help(linearHypothesis)
#------------------------------------------------
#Lower Tail Test of Population Mean with Known Variance
#QUESTION-Suppose the manufacturer claims that the mean lifetime of a light bulb is more than 10,000 hours. In a sample of 30 light bulbs, it was found that they only last 9,900 hours on average. Assume the population standard deviation is 120 hours. At .05 significance level, can we reject the claim by the manufacturer?
#The null hypothesis of the lower tail test of the population mean can be expressed as follows:  μ ≥ μ0
xbar = 9900            # sample mean
mu0 = 10000            # hypothesized value
sigma = 120            # population standard deviation
n = 30
#z = (xbar−mu0)/(sigma/sqrt(n))
z = (xbar−mu0)/(sigma/sqrt(n))#test statistics
z
#  We then compute the critical value at .05 significance level.
alpha = .05
z.alpha = qnorm(1−alpha)
(-z.alpha)  # # critical value
#Alternative Solution
pval = pnorm(z)
pval
